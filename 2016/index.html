<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="../../favicon.ico">

    <title>COLING 2016 Workshop on Speech-Centric Natural Language Processing (SCNLP)</title>

    <!-- Bootstrap core CSS -->
    <link href="./dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="navbar-fixed-top.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    
  <style>
 
  </style>
  </head>

  <body >
    <!-- Fixed navbar --><nav class="navbar navbar-default navbar-fixed-top">
<div class="container">
<div class="navbar-header"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar"> <span class="sr-only">Toggle navigation</span> </button> <a class="navbar-brand" href="#">SCNLP</a></div>
<div id="navbar" class="navbar-collapse collapse">
<ul class="nav navbar-nav">
<li class="active"><a href="#">Home</a></li>
<li><a href="#cfp">Call for Papers</a></li>
<li><a href="#committee">Committee</a></li>
<li><a href="#about">About</a></li>
<li><a href="#contact">Contact Us</a></li>
</ul>
</div>
<!--/.nav-collapse --></div>
</nav>
<div class="container"><!-- Main component for a primary marketing message or call to action -->
<div class="jumbotron">
<h2>2016 1st Workshop on Speech-Centric Natural Language Processing (SCNLP)</h2>
<p>December 11, 2016, Osaka, Japan</p>
<p>We are happy to introduce the 1st SCNLP workshop, which will be held at at <a href="http://coling2016.anlp.jp/">COLING</a>!</p>
<p>SCNLP's goal is to unite the ASR and NLP communities to discuss new frameworks for exploiting the rich information present in the speech signal to improve the capabilities of natural language processing applications such as conversational agents, question-answering systems, machine translation, and search. In addition to acoustic environment information, the audio signal may contain speaker-specific features which may identify the emotional state, demographic information, and the presence of uncertainty in the speaker&rsquo;s utterance: features which may influence the output of the NLP component. SCNLP encourages novel&nbsp;contributions that revisit the conventional NLP problems with a focus on incorporating the richness of spoken language, as well as contributions that promote cross-fertilization between statistical methods for ASR and NLP.</p>
<p>We look forward to seeing you!</p>
</div>
<h2>Workshop Organizers</h2>
<ul>
<li>Nicholas Ruiz (Interactions, USA)</li>
<li>Srinivas Bangalore (Interactions, USA)</li>
</ul>
<hr /><!--
<h2 style="padding-top: 50px; margin-top: -50px;">Invited Speakers</h2>
<ul>
<li><a href="http://research.microsoft.com/en-us/um/people/minchang/">Ming-Wei Chang</a> (Microsoft Research)</li>
<li><a href="http://www.let.rug.nl/~bplank/">Barbara Plank</a> (University of Copenhagen)</li>
<li><a href="http://www2.nict.go.jp/univ-com/info_analysis/member/torisawa/index-e.html">Kentaro Torisawa</a> (National Institute of Information and Communications Technology)</li>
</ul>
<hr />
-->
<h2>Important Dates</h2>
<ul>
<li>June 2016: First call for workshop papers</li>
<li><strike>September 25 2016</strike> <strong>Extended to October 2 2016</strong>: Workshop paper due</li>
<li>October 23 2016: Notification of acceptance</li>
<li>November 6 2016: Camera-ready due</li>
<li>November 30, 2016: Official proceedings publication date</li>
<li>December 11, 2016: Workshop date</li>
</ul>
<hr />
<a name="cfp"><h2>Call for Papers</h2></a>
<p>We invite submissions of <strong>both long and short papers on original and unpublished work.</strong> Similar to the main conference, submissions are <strong>limited to 8 pages</strong>. All accepted submissions will be presented as posters. Additionally, selected submissions will be presented orally.</p>
<p>Topics of interest include but are not limited to:</p>
<ul>
<li>Joint ASR/NLP modeling using deep learning</li>
<li>Spoken query reformulation for Question/Answering systems</li>
<li>ASR error modeling and evaluation for NLP</li>
<li>Emotive Speech Synthesis for Spoken dialogue systems</li>
<li>Word-sense disambiguation for speech</li>
<li>Information extraction from speech transcripts</li>
<li>Domain adaptation (Adapting textual NLP training data to speech-centric tasks)</li>
<li>Spoken language translation</li>
<li>Rich speech transcription</li>
<li>Disfluency and uncertainty detection</li>
<li>NLP with ASR lattices/confusion networks</li>
<li>Speech segmentation for NLP</li>
<li>Discourse and Speech Processing</li>
</ul>
<p>All submissions should conform to <a href="http://coling2016.anlp.jp/#instructions">COLING 2016 style guidelines</a>. Long and short paper submissions must be anonymized. Please submit your papers at <a href="https://www.softconf.com/coling2016/SCNLP/">https://www.softconf.com/coling2016/SCNLP/</a>.

<hr />
<a name="committee"><h2>Program Committee</h2></a>
<!-- (The list is growing) -->
<ul class="list-unstyled">
<li>Lo&iuml;c Barrault (Laboratoire d'Informatique de l'Universit&eacute; du Maine)</li>
<li>Frederic B&eacute;chet (Aix Marseille Universit&eacute;)</li>
<li>Francisco Casacuberta (Universitat Polit&egrave;cnica de Val&egrave;ncia)</li>
<li>Giuseppe di Fabbrizio (Amazon, USA)</li>
<li>Peter Heeman (Oregon Health &amp; Science University, USA)
<li>Julia Hirschberg (Columbia University, USA)</li>
<li>Tatsuya Kawahara (Kyoto University)</li>
<li>Gakuto Kurata (IBM Research, Tokyo)</li>
<li>Yang Liu (University of Texas at Dallas)</li>
<li>Yajie Miao (Carnegie Mellon University)</li>
<li>Alexandros Potamianos (National Technical University of Athens)</li>
<li>Giuseppe Riccardi (University of Trento)</li>
<li>Isabel Trancoso (L2F, Lisbon)</li>
<li>Jason Williams (Microsoft Research, USA)</li>
</ul>
<hr />
<a name="about"><h2>Motivation</h2></a>
<p>Language technologies have come of age and are playing an increasingly vital role in our everyday lives. From human-machine conversational technologies to text and speech analytics, we are routinely in contact with language technologies, with or without our knowledge. This progress is directly attributable to robust accuracy improvements in the automatic speech recognition (ASR) and natural language processing (NLP) communities. While both communities use data-driven techniques to achieve robustness, the opportunity to jointly optimize the robustness in a majority of speech-driven natural language processing systems is widely ignored; instead speech-centric NLP tasks predominantly rely on a sequential application of independently optimized ASR and NLP tools.</p>

<p>While advancements in ASR have been demonstrated through significant reductions in word error rate evaluation scores for a variety of word transcription tasks, the standard ASR evaluation metric does not account for the varied uses of the transcriptions in downstream NLP tasks. Furthermore, the impact of rich para-lexical information latent in speech on downstream tasks has not received sufficient attention due to the disproportionate emphasis on word transcription in speech processing. Likewise, although NLP research has begun to address the problem of extra-grammatical and telegraphic texts in user-generated social media, the traditional focus of the field has been on well-edited written texts. As a result, the majority of speech-centric NLP systems do not exploit the weighted multi-string hypotheses typically produced by speech recognizers, but instead treat the problem as a simple ASR-NLP pipeline which transforms ASR outputs into text-like input, such as N-best word hypotheses, prior to processing with conventional NLP tools. Such approaches result in a suboptimal quality of output with potentially significant room for improvement by leveraging the rich information available from speech input.</p>

<p>The purpose of this workshop is to unite the ASR and NLP communities to discuss new frameworks for exploiting the rich information present in the speech signal to improve the capabilities of natural language processing applications such as conversational agents, question-answering systems, machine translation, and search. In addition to acoustic environment information, the audio signal may contain speaker-specific features which may identify the emotional state, demographic information, and the presence of uncertainty in the speaker’s utterance: features which may influence the output of the NLP component. For example, a dialogue system may infer negative feedback from the consumer’s responses and switch to a different dialogue strategy to obtain the necessary information to carry out its task. We invite contributions that revisit the conventional NLP problems with a focus on incorporating the richness of spoken language, as well as contributions that promote cross-fertilization between statistical methods for ASR and NLP.</p>
<hr />
<a name="contact"><h2>Contact</h2></a>
Send us an email at scnlp {AT} interactions.com.

</div>
<!-- /container -->
<p>&nbsp;</p>
<!-- Bootstrap core JavaScript
    ================================================== -->
<p>&nbsp;</p>
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<script src="./dist/js/bootstrap.min.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>