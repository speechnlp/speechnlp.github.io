<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="../../favicon.ico">

    <title>EMNLP 2017 Workshop on Speech-Centric Natural Language Processing (SCNLP)</title>

    <!-- Bootstrap core CSS -->
    <link href="./dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="navbar-fixed-top.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    
  <style>
 
  </style>
  </head>

  <body >
    <!-- Fixed navbar --><nav class="navbar navbar-default navbar-fixed-top">
<div class="container">
<div class="navbar-header"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar"> <span class="sr-only">Toggle navigation</span> </button> <a class="navbar-brand" href="#">SCNLP</a></div>
<div id="navbar" class="navbar-collapse collapse">
<ul class="nav navbar-nav">
<li class="active"><a href="#">Home</a></li>
<li><a href="#cfp">Call for Papers</a></li>
<li><a href="#committee">Committee</a></li>
<li><a href="#about">About</a></li>
<li><a href="#contact">Contact Us</a></li>
</ul>
</div>
<!--/.nav-collapse --></div>
</nav>
<div class="container"><!-- Main component for a primary marketing message or call to action -->
<div class="jumbotron">
<h2>2017 1st Workshop on Speech-Centric Natural Language Processing (SCNLP)</h2>
<p>September 7, 2017, Copenhagen, Denmark</p>
<p>We are happy to introduce the 1st SCNLP workshop, which will be held at <a href="http://emnlp2017.net/">EMNLP 2017</a>!</p>
<p>SCNLP's goal is to unite the ASR and NLP communities to discuss new frameworks for exploiting the rich information present in the speech signal to improve the capabilities of natural language processing applications such as conversational agents, question-answering systems, machine translation, and search. SCNLP encourages novel contributions that revisit the conventional NLP problems with a focus on incorporating the richness of spoken language, as well as contributions that promote cross-fertilization between statistical methods for ASR and NLP.</p> 

<p>We envision SCNLP as a platform to promote collaboration between the ASR and NLP communities and to seek ways to lower the barrier of entry for researchers interested in working in the exciting intersection between Speech and Natural Language Processing.</p>
<p>The inaugural workshop is hosted on NLP home territory. Future iterations of the workshop will alternate between Speech and NLP venues to encourage the cross-fertilization of ideas.</p>
<p>We look forward to seeing you at EMNLP!</p>
</div>
<h2>Workshop Organizers</h2>
<ul>
<li>Nicholas Ruiz (Interactions, USA)</li>
<li>Srinivas Bangalore (Interactions, USA)</li>
</ul>
<hr /><!--
<h2 style="padding-top: 50px; margin-top: -50px;">Invited Speakers</h2>
<ul>
<li><a href="http://research.microsoft.com/en-us/um/people/minchang/">Ming-Wei Chang</a> (Microsoft Research)</li>
<li><a href="http://www.let.rug.nl/~bplank/">Barbara Plank</a> (University of Copenhagen)</li>
<li><a href="http://www2.nict.go.jp/univ-com/info_analysis/member/torisawa/index-e.html">Kentaro Torisawa</a> (National Institute of Information and Communications Technology)</li>
</ul>
<hr />
-->
<h2>Important Dates</h2>
<ul>
<li>February 2017: First call for workshop papers</li>
<li>June 2 2017: Workshop papers due</li>
<li>June 30 2017: Notification of acceptance</li>
<li>July 14 2017: Camera-ready due</li>
<li>September 7 2017: Workshop date</li>
</ul>
<hr />
<a name="cfp"><h2>Call for Papers</h2></a>
<p>We invite submissions of <strong>both long and short papers on original and unpublished work.</strong> Similar to the main conference, submissions are <strong>limited to 8 pages</strong>. All accepted submissions will be presented as posters. Additionally, selected submissions will be presented orally.</p>
<p>Topics of interest include but are not limited to:</p>
<ul>
<li>Joint ASR/NLP modeling using deep learning</li>
<li>Spoken query reformulation for Question/Answering systems</li>
<li>ASR error modeling and evaluation for NLP</li>
<li>Emotive Speech Synthesis for Spoken dialogue systems</li>
<li>Word-sense disambiguation for speech</li>
<li>Information extraction from speech transcripts</li>
<li>Domain adaptation (Adapting textual NLP training data to speech-centric tasks)</li>
<li>Spoken language translation</li>
<li>Rich speech transcription</li>
<li>Disfluency and uncertainty detection</li>
<li>NLP with ASR lattices/confusion networks</li>
<li>Speech segmentation for NLP</li>
<li>Discourse and Speech Processing</li>
</ul>
<p>All submissions should conform to the EMNLP 2017 two-column format, using the provided LaTeX style files (they will be posted on the conference site). Authors are strongly discouraged from modifying the style files. Please do not use other templates (e.g., Word). Submissions that do not conform to the required styles, including paper size, margin width, and font size restrictions, will be rejected without review..

<hr />
<a name="committee"><h2>Program Committee</h2></a>
<p>We are excited to have a strong program committee consisting of research leaders spanning the Speech and NLP communities.
<br/>
This list is still growing.</p>
<ul class="list-unstyled">
<li>Francisco Casacuberta   (Universitat Politècnica de València)</li>
<li>Eric Fosler-Lussier (The Ohio State University, USA)</li>
<li>Dilek Hakkani-Tür   (Google, USA)</li>
<li>Xiaodong He (Microsoft Research, USA)</li>
<li>Peter Heeman    (Oregon Health &amp; Science University, USA)</li>
<li>Julia Hirschberg    (Columbia University, USA)</li>
<li>Preethi Jyothi  (IIT Bombay, India)</li>
<li>Gakuto Kurata   (IBM Research, Tokyo, Japan)</li>
<li>Lin-shan Lee    (National Taiwan University)</li>
<li>Yang Liu    (University of Texas at Dallas, USA)</li>
<li>Raymond Mooney  (University of Texas at Austin, USA)</li>
<li>Satoshi Nakamura    (Nara Institute of Science and Technology, Japan)</li>
<li>Mari Ostendorf  (University of Washington, USA)</li>
<li>Giuseppe Riccardi   (University of Trento, Italy)</li>
<li>Andrew Rosenberg    (IBM T.J. Watson Research Center)</li>
<li>Isabel Trancoso (Laborat&ograve;rio de Sistemas de Lingua Falada, Lisbon)</li>
<li>Jason Williams  (Microsoft Research, USA)</li>
</ul>
<hr />
<a name="about"><h2>Motivation</h2></a>
<p>Language technologies have come of age and are playing an increasingly vital role in our everyday lives. From human-machine conversational technologies to text and speech analytics, we are routinely in contact with language technologies, with or without our knowledge. This progress is directly attributable to robust accuracy improvements in the automatic speech recognition (ASR) and natural language processing (NLP) communities. While both communities use data-driven techniques to achieve robustness, the opportunity to jointly optimize the robustness in a majority of speech-driven natural language processing systems is widely ignored; instead speech-centric NLP tasks predominantly rely on a sequential application of independently optimized ASR and NLP tools.</p>

<p>While advancements in ASR have been demonstrated through significant reductions in word error rate evaluation scores for a variety of word transcription tasks, the standard ASR evaluation metric does not account for the varied uses of the transcriptions in downstream NLP tasks. Furthermore, the impact of rich para-lexical information latent in speech on downstream tasks has not received sufficient attention due to the disproportionate emphasis on word transcription in speech processing. Likewise, although NLP research has begun to address the problem of extra-grammatical and telegraphic texts in user-generated social media, the traditional focus of the field has been on well-edited written texts. As a result, the majority of speech-centric NLP systems do not exploit the weighted multi-string hypotheses typically produced by speech recognizers, but instead treat the problem as a simple ASR-NLP pipeline which transforms ASR outputs into text-like input, such as N-best word hypotheses, prior to processing with conventional NLP tools. Such approaches result in a suboptimal quality of output with potentially significant room for improvement by leveraging the rich information available from speech input.</p>

<p>The purpose of this workshop is to unite the ASR and NLP communities to discuss new frameworks for exploiting the rich information present in the speech signal to improve the capabilities of natural language processing applications such as conversational agents, question-answering systems, machine translation, and search. In addition to acoustic environment information, the audio signal may contain speaker-specific features which may identify the emotional state, demographic information, and the presence of uncertainty in the speaker’s utterance: features which may influence the output of the NLP component. For example, a dialogue system may infer negative feedback from the consumer’s responses and switch to a different dialogue strategy to obtain the necessary information to carry out its task. We invite contributions that revisit the conventional NLP problems with a focus on incorporating the richness of spoken language, as well as contributions that promote cross-fertilization between statistical methods for ASR and NLP.</p>
<hr />
<a name="contact"><h2>Contact</h2></a>
Send us an email at scnlp {AT} interactions.com.

</div>
<!-- /container -->
<p>&nbsp;</p>
<!-- Bootstrap core JavaScript
    ================================================== -->
<p>&nbsp;</p>
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<script src="./dist/js/bootstrap.min.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>