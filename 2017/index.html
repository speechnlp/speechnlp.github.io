<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="../../favicon.ico">

    <title>EMNLP 2017 Workshop on Speech-Centric Natural Language Processing (SCNLP)</title>

    <!-- Bootstrap core CSS -->
    <link href="./dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="navbar-fixed-top.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    
  <style>
 
  </style>
  </head>

  <body >
    <!-- Fixed navbar --><nav class="navbar navbar-default navbar-fixed-top">
<div class="container">
<div class="navbar-header"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar"> <span class="sr-only">Toggle navigation</span> </button> <a class="navbar-brand" href="#">SCNLP</a></div>
<div id="navbar" class="navbar-collapse collapse">
<ul class="nav navbar-nav">
<li class="active"><a href="#">Home</a></li>
<li><a href="#proceedings">Proceedings</a></li>
<li><a href="#schedule">Schedule</a></li>
<li><a href="#cfp">Call for Papers</a></li>
<li><a href="#committee">Committee</a></li>
<li><a href="#about">About</a></li>
<li><a href="#harassment">Anti-Harassment</a></li>
<li><a href="#contact">Contact Us</a></li>
</ul>
</div>
<!--/.nav-collapse --></div>
</nav>
<div class="container"><!-- Main component for a primary marketing message or call to action -->
<div class="jumbotron">
<h2>2017 1st Workshop on Speech-Centric Natural Language Processing (SCNLP)</h2>
<p>September 7, 2017, Copenhagen, Denmark</p>

<p>We are happy to introduce the 1st SCNLP workshop, which was held at <a href="http://emnlp2017.net/">EMNLP 2017</a>!</p>
<p>SCNLP's goal is to unite the ASR and NLP communities to discuss new frameworks for exploiting the rich information present in the speech signal to improve the capabilities of natural language processing applications such as conversational agents, question-answering systems, machine translation, and search. SCNLP encourages novel contributions that revisit the conventional NLP problems with a focus on incorporating the richness of spoken language, as well as contributions that promote cross-fertilization between statistical methods for ASR and NLP.</p> 

<p>We envision SCNLP as a platform to promote collaboration between the ASR and NLP communities and to seek ways to lower the barrier of entry for researchers interested in working in the exciting intersection between Speech and Natural Language Processing.</p>
<p>The inaugural workshop is hosted on NLP home territory. Future iterations of the workshop will alternate between Speech and NLP venues to encourage the cross-fertilization of ideas.</p>
<!-- <p>We look forward to seeing you at EMNLP!</p> -->
</div>
<hr /><!--
<h2 style="padding-top: 50px; margin-top: -50px;">Invited Speakers</h2>
<ul>
<li><a href="http://research.microsoft.com/en-us/um/people/minchang/">Ming-Wei Chang</a> (Microsoft Research)</li>
<li><a href="http://www.let.rug.nl/~bplank/">Barbara Plank</a> (University of Copenhagen)</li>
<li><a href="http://www2.nict.go.jp/univ-com/info_analysis/member/torisawa/index-e.html">Kentaro Torisawa</a> (National Institute of Information and Communications Technology)</li>
</ul>
<hr />
-->
<!-- <h2>Important Dates</h2> -->
<!-- <h4>[August 9]</h4>
<p>The workshop schedule has been posted.</p>

<h4>[July 5]</h4>
<p>We need a few more days for paper review. We have pushed our notification date back to <strong>July 7, 2017</strong>. We apologize for the inconvenience.</p>

<h4>[June 2]</h4>
<p>Due to several requests from our participants, we are <strong>extending our paper submission deadline until <font color="red">June 9, 2017</font></strong>. Thanks for your participation!

<h4>[February 17]</h4>
<p>We recently added the ACL <a href="harassment">Anti-Harassment Policy</a> to this page.
We stand behind our higher calling to be kind stewards of knowledge and wisdom by valuing the researcher as well as his or her research.</p>

<h4>[February 15]</h4>
<p><a href="https://www.softconf.com/emnlp2017/scnlp">Paper submission portal is open!</a></p> -->

<!-- <h4>Dates</h4> -->
<!-- <ul>
<li>February 2017: First call for workshop papers</li>
<li><strong>June 9 2017</strong>: Workshop papers due (Submit your papers <a href="https://www.softconf.com/emnlp2017/scnlp">here</a>.)</li>
<li>July 8, 2017 <strike>June 30 2017</strike>: Notification of acceptance</li>
<li>July 14 2017: Camera-ready due</li>
<li>September 7 2017: Workshop date</li>
</ul>
<hr /> -->

<a name="proceedings"><h2>Proceedings</h2></a>
<p>The proceedings of SCNLP 2017 may be downloaded [<a href="papers/W17-46.pdf">here</a>].</p>
<p>For specific papers, please download them from the <a href="#schedule">schedule</a> below.</p>

<a name="schedule"><h2>Workshop Schedule &amp; Logistics</h2></a>
<p>The workshop took place in the <b>Kastrup Airport</b> room in the &quot;CPH Conference&quot; facility.
The CPH Conference was a part of DGI-byen, located right next to the conference venue.
There was also a round-table session to discuss relevant issues in speech-centric NLP.</p>

<ul>
<li>08:50 - 09:00     Opening Remarks</li>
<li>09:00 - 10:00    Invited Talk</li>
    <ul>
    <li><h4>Modelling turn-taking in spoken interaction</h4>
        
    <i><a href="http://www.speech.kth.se/~gabriel/" target="_blank">Gabriel Skantze</a></i>
      <br/>KTH Royal Institute of Technology in Stockholm
      <br/><br/>
      <p>One of the most fundamental aspects of spoken dialogue is the organization of speaking between the participants. Since it is difficult to speak and listen at the same time, the interlocutors need to take turns speaking, and this turn-taking has to be coordinated somehow. This coordination is achieved using verbal and non-verbal signals, expressed in the face and voice, including syntax, prosody and gaze. Contrary to this, spoken dialogue systems typically use a very simplistic, silence-based model of turn-taking, which often results in interruptions or sluggish responses. In this talk, I will give an overview of several studies on how to model turn-taking in spoken interaction, with a special focus on multi-modal, human-robot interaction. These studies show that humans in interaction with a human-like robot make use of the same coordination signals typically found in studies on human-human interaction, and that it is possible to automatically detect and combine these cues to facilitate real-time coordination. The studies also show that humans react naturally to such signals when used by a robot, without being given any special instructions. Finally, I will present recent work on how Recurrent Neural Networks can be used to train a predictive, continuous model of turn-taking from human-human interaction data. </p>
    </li>
    </ul>
<li>10:00 - 10:30       Session I</li>
    <ul>
    <li>
    <h4>Functions of Silences towards Information Flow in Spoken Conversation</h4>
        <a href="papers/W17-4601.pdf">[PDF]</a>
      <!-- </a> --><br/>
      <em>Shammur Absar Chowdhury,&nbsp;Evgeny Stepanov,&nbsp;Morena Danieli,&nbsp;Giuseppe Riccardi</em><br>
      University of Trento
    </li>
    </ul>
<li>10:30 - 11:00       Coffee Break</li>
<li>11:00 - 12:30       Session II</li>
    <ul>
    <li>
        <h4>Encoding Word Confusion Networks with Recurrent Neural Networks for Dialog State Tracking</h4> 
        <a href="papers/W17-4602.pdf">[PDF]</a>
        <a href="papers/W17-4602-slides.pdf">[Slides]</a><br/>
      
      <em>Glorianna Jagfeld<sup>1</sup> and Ngoc Thang Vu<sup>2</sup></em><br>
      <sup>1</sup>Institute for Natural Language Processing, University of Stuttgart, <sup>2</sup>University of Stuttgart
    </li>
    <li>
        <h4>Analyzing Human and Machine Performance In Resolving Ambiguous Spoken Sentences</h4> 
        <a href="papers/W17-4603.pdf">[PDF]</a>
        <a href="papers/W17-4603-slides.pdf">[PDF]</a><br/>
      
      <em>Hussein Ghaly<sup>1</sup> and Michael Mandel<sup>2</sup></em><br>
      <sup>1</sup>City University of New York, <sup>2</sup>Brooklyn College, CUNY
    </li>
     <li>   
        <h4>Parsing transcripts of speech</h4> 
        <a href="papers/W17-4604.pdf">[PDF]</a>
        <a href="papers/W17-4604-slides.pdf">[Slides]</a>
        <a href="https://www.ortolang.fr/market/corpora/ortolang-000913">[Data]</a><br/>
      
      <em>Andrew Caines<sup>1</sup>,&nbsp;Michael McCarthy<sup>2</sup>,&nbsp;Paula Buttery<sup>1</sup></em><br>
      <sup>1</sup>University of Cambridge, <sup>2</sup>University of Nottingham
    </li>
    <li>    
    <h4>Enriching ASR Lattices with POS Tags for Dependency Parsing</h4> 
    <a href="papers/W17-4605.pdf">[PDF]</a><br/>
      
      <em>Moritz Stiefel<sup>1</sup> and Ngoc Thang Vu<sup>2</sup></em><br>
      <sup>1</sup>IMS, University of Stuttgart, <sup>2</sup>University of Stuttgart
      </li>
    </ul>
<li>12:30 - 14:00       Lunch - Øksnehallen</li>
<li>14:00 - 15:30       Session III</li>
    <ul>
    <li>
    <h4>End-to-End Information Extraction without Token-Level Supervision</h4> 
        <a href="papers/W17-4606.pdf">[PDF]</a>
        <a href="papers/W17-4606-slides.pdf">[Slides]</a><br/>
      
      <em>Rasmus Berg Palm<sup>1</sup>,&nbsp;Dirk Hovy<sup>2</sup>,&nbsp;Florian Laws<sup>3</sup>,&nbsp;Ole Winther<sup>1</sup></em><br>
      <sup>1</sup>Technical University Denmark, <sup>2</sup>Center for Language Technology, University of Copenhagen, <sup>3</sup>University of Stuttgart
     </li>
     <li>   
        <h4>Spoken Term Discovery for Language Documentation using Translations</h4> 
        <a href="papers/W17-4607.pdf">[PDF]</a>
        <a href="papers/W17-4607-slides.pptx">[Slides]</a><br/>
      
      <em>Antonios Anastasopoulos<sup>1</sup>,&nbsp;Sameer Bansal<sup>2</sup>,&nbsp;David Chiang<sup>1</sup>,&nbsp;Sharon Goldwater<sup>2</sup>,&nbsp;Adam Lopez<sup>2</sup></em><br>
      <sup>1</sup>University of Notre Dame, <sup>2</sup>University of Edinburgh
     </li>
     <li>   
        <h4>Amharic-English Speech Translation in Tourism Domain</h4> 
        <a href="papers/W17-4608.pdf">[PDF]</a>
        <a href="papers/W17-4608-slides.pdf">[Slides]</a>
      
      <em>Michael Melese<sup>1</sup>,&nbsp;Laurent Besacier<sup>2</sup>,&nbsp;Million Meshesha<sup>1</sup></em><br>
      <sup>1</sup>Addis Ababa University, Addis Ababa, Ethiopia, <sup>2</sup>LIG Laboratory, UJF, BP53, 38041 Grenoble Cedex 9, France
     </li>
     <li>   
        <h4>Speech- and Text-driven Features for Automated Scoring of English Speaking Tasks</h4> 
        <a href="papers/W17-4609.pdf">[PDF]</a>
        <a href="papers/W17-4609-slides.pdf">[Slides]</a><br/>
      
      <em>Anastassia Loukina,&nbsp;Nitin Madnani,&nbsp;Aoife Cahill</em><br>
      Educational Testing Service
    </li>
    </ul>
<li>15:30 - 16:00    Coffee Break</li>
<li>16:00 - 16:25       Session IV</li>
    <ul>
    <li>
    <h4>Improving coreference resolution with automatically predicted prosodic information</h4> 
    <a href="papers/W17-4610.pdf">[PDF]</a><br/>
      
      <em>Ina Roesiger,&nbsp;Sabrina Stehwien,&nbsp;Arndt Riester,&nbsp;Ngoc Thang Vu</em><br>
      University of Stuttgart
    </li>
    </ul>
<li>16:25 - 17:50       Round-table: Issues in Speech-centric NLP</li>
<li>17:50 - 18:00       Closing</li>
</ul>




<hr />
<a name="cfp"><h2>Call for Papers</h2></a>
<p>We invite submissions of <strong>both long and short papers on original and unpublished work.</strong> Similar to the main conference, submissions are <strong>limited to 8 pages</strong>. All accepted submissions will be presented as posters. Additionally, selected submissions will be presented orally.</p>
<p>Topics of interest include but are not limited to:</p>
<ul>
<li>Joint ASR/NLP modeling using deep learning</li>
<li>Spoken query reformulation for Question/Answering systems</li>
<li>ASR error modeling and evaluation for NLP</li>
<li>Emotive Speech Synthesis for Spoken dialogue systems</li>
<li>Word-sense disambiguation for speech</li>
<li>Information extraction from speech transcripts</li>
<li>Domain adaptation (Adapting textual NLP training data to speech-centric tasks)</li>
<li>Spoken language translation</li>
<li>Rich speech transcription</li>
<li>Disfluency and uncertainty detection</li>
<li>NLP with ASR lattices/confusion networks</li>
<li>Speech segmentation for NLP</li>
<li>Discourse and Speech Processing</li>
</ul>
<p>All submissions should conform to the EMNLP 2017 two-column format, using the provided LaTeX style files (they will be posted on the conference site). Authors are strongly discouraged from modifying the style files. Please do not use other templates (e.g., Word). Submissions that do not conform to the required styles, including paper size, margin width, and font size restrictions, will be rejected without review..

<p>Our paper submission portal is currently open. Visit <a href="https://www.softconf.com/emnlp2017/scnlp">https://www.softconf.com/emnlp2017/scnlp</a> to submit your paper.</p>

<hr />
<a name="committee"><h2>Program Committee</h2></a>
<p>We are excited to have a strong program committee consisting of research leaders spanning the Speech and NLP communities.
<br/>
<h3>Workshop Organizers</h3>
<ul class="list-unstyled">
<li>Nicholas Ruiz (Interactions, USA)</li>
<li>Srinivas Bangalore (Interactions, USA)</li>
</ul>
<h3>Program Committee</h3>
<ul class="list-unstyled">
<li>Francisco Casacuberta   (Universitat Politècnica de València)</li>
<li>Eric Fosler-Lussier (The Ohio State University, USA)</li>
<li>Dilek Hakkani-Tür   (Google, USA)</li>
<li>Xiaodong He (Microsoft Research, USA)</li>
<li>Peter Heeman    (Oregon Health &amp; Science University, USA)</li>
<li>Julia Hirschberg    (Columbia University, USA)</li>
<li>Preethi Jyothi  (IIT Bombay, India)</li>
<li>Gakuto Kurata   (IBM Research, Tokyo, Japan)</li>
<li>Lin-shan Lee    (National Taiwan University)</li>
<li>Yang Liu    (University of Texas at Dallas, USA)</li>
<li>Karen Livescu   (Toyota Technological Institute at Chicago, USA)</li>
<li>Raymond Mooney  (University of Texas at Austin, USA)</li>
<li>Satoshi Nakamura    (Nara Institute of Science and Technology, Japan)</li>
<li>Mari Ostendorf  (University of Washington, USA)</li>
<li>Giuseppe Riccardi   (University of Trento, Italy)</li>
<li>Andrew Rosenberg    (IBM T.J. Watson Research Center)</li>
<li>Isabel Trancoso (Laborat&ograve;rio de Sistemas de Lingua Falada, Lisbon)</li>
<li>Jason Williams  (Microsoft Research, USA)</li>
</ul>
<hr />
<a name="about"><h2>Motivation</h2></a>
<p>Language technologies have come of age and are playing an increasingly vital role in our everyday lives. From human-machine conversational technologies to text and speech analytics, we are routinely in contact with language technologies, with or without our knowledge. This progress is directly attributable to robust accuracy improvements in the automatic speech recognition (ASR) and natural language processing (NLP) communities. While both communities use data-driven techniques to achieve robustness, the opportunity to jointly optimize the robustness in a majority of speech-driven natural language processing systems is widely ignored; instead speech-centric NLP tasks predominantly rely on a sequential application of independently optimized ASR and NLP tools.</p>

<p>While advancements in ASR have been demonstrated through significant reductions in word error rate evaluation scores for a variety of word transcription tasks, the standard ASR evaluation metric does not account for the varied uses of the transcriptions in downstream NLP tasks. Furthermore, the impact of rich para-lexical information latent in speech on downstream tasks has not received sufficient attention due to the disproportionate emphasis on word transcription in speech processing. Likewise, although NLP research has begun to address the problem of extra-grammatical and telegraphic texts in user-generated social media, the traditional focus of the field has been on well-edited written texts. As a result, the majority of speech-centric NLP systems do not exploit the weighted multi-string hypotheses typically produced by speech recognizers, but instead treat the problem as a simple ASR-NLP pipeline which transforms ASR outputs into text-like input, such as N-best word hypotheses, prior to processing with conventional NLP tools. Such approaches result in a suboptimal quality of output with potentially significant room for improvement by leveraging the rich information available from speech input.</p>

<p>The purpose of this workshop is to unite the ASR and NLP communities to discuss new frameworks for exploiting the rich information present in the speech signal to improve the capabilities of natural language processing applications such as conversational agents, question-answering systems, machine translation, and search. In addition to acoustic environment information, the audio signal may contain speaker-specific features which may identify the emotional state, demographic information, and the presence of uncertainty in the speaker’s utterance: features which may influence the output of the NLP component. For example, a dialogue system may infer negative feedback from the consumer’s responses and switch to a different dialogue strategy to obtain the necessary information to carry out its task. We invite contributions that revisit the conventional NLP problems with a focus on incorporating the richness of spoken language, as well as contributions that promote cross-fertilization between statistical methods for ASR and NLP.</p>
<hr />

<a name="harassment"><h2>Anti-Harassment Policy</h2></a>
<p>The open exchange of ideas, the freedom of thought and expression, and respectful scientific debate are central to the aims and goals of the ACL. These require a community and an environment that recognizes the inherent worth of every person and group, that fosters dignity, understanding, and mutual respect, and that embraces diversity. For these reasons, ACL is dedicated to providing a harassment-free experience for all the members, as well as participants at our events and in our programs.</p>

<p>Harassment and hostile behavior are unwelcome at any ACL conference, associated event, or in ACL-affiliated on-line discussions. This includes: speech or behavior that intimidates, creates discomfort, or interferes with a person's participation or opportunity for participation in a conference or an event. We aim for ACL-related activities to be an environment where harassment in any form does not happen, including but not limited to: harassment based on race, gender, religion, age, color, appearance, national origin, ancestry, disability, sexual orientation, or gender identity. Harassment includes degrading verbal comments, deliberate intimidation, stalking, harassing photography or recording, inappropriate physical contact, and unwelcome sexual attention. The policy is not intended to inhibit challenging scientific debate, but rather to promote it through ensuring that all are welcome to participate in shared spirit of scientific inquiry.</p>

<p>It is the responsibility of the community as a whole to promote an inclusive and positive environment for our scholarly activities. In addition, anyone who experiences harassment or hostile behavior may contact any current member of the <a href="https://www.aclweb.org/portal/about">ACL Executive Committee</a> or contact Priscilla Rasmussen (acl [AT] aclweb.org), who is usually available at the registration desk during ACL conferences. Members of the executive committee will be instructed to keep any such contact in strict confidence, and those who approach the committee will be consulted before any actions are taken.</p>
<hr/>

<a name="contact"><h2>Contact</h2></a>
Send us an email at scnlp {AT} interactions.com.

</div>
<!-- /container -->
<p>&nbsp;</p>
<!-- Bootstrap core JavaScript
    ================================================== -->
<p>&nbsp;</p>
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<script src="./dist/js/bootstrap.min.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>